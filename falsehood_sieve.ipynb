{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2846428f",
   "metadata": {},
   "source": [
    "# Naive Classifier for Fake news recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09bfabd",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b9dcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "library(stopwords)\n",
    "library(tidytext)\n",
    "library(stringr)\n",
    "library(purrr)\n",
    "library(magrittr)\n",
    "library(parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c6d5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "numCores <- detectCores()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1142bb",
   "metadata": {},
   "source": [
    "# Reading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0e1a24",
   "metadata": {},
   "source": [
    "### Kaggle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa86fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.filename <- 'dataset/archive/train.csv'\n",
    "test.filename <- 'dataset/archive/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0f137a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.df <- read.delim(train.filename, sep = ',')\n",
    "test.df <- read.delim(test.filename, sep = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e561cbf3",
   "metadata": {},
   "source": [
    "### Second dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f1617ef6",
   "metadata": {},
   "source": [
    "train2.filename <- 'dataset/fake-news/train.csv'\n",
    "test2.filename <- 'dataset/fake-news/test.csv'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f3393439",
   "metadata": {},
   "source": [
    "train2.df <- read.delim(train2.filename, sep = ',')\n",
    "test2.df <- read.delim(test2.filename, sep = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6efc43",
   "metadata": {},
   "source": [
    "# Display the train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ff4e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(train.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e832411",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(test.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc80813",
   "metadata": {},
   "source": [
    "# Splitting the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e24744e-455b-4d1a-bddf-e4d70d4015b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle\n",
    "set.seed(29062023)\n",
    "train.df=train.df[sample(1:nrow(train.df), replace = F),] # shuffle the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53de2aa4-33ba-4007-b676-4c9213b4f25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set splitting percentages\n",
    "perc_split <- 0.8  # set splitting percentages\n",
    "n_rows <- nrow(train.df)\n",
    "n_rows_train <- floor(n_rows * perc_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c87399-c8de-4dda-b79f-18770080e017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting\n",
    "train.df.train <- train.df[1:n_rows_train, ]\n",
    "train.df.validation <- train.df[-c(1:n_rows_train), ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9036ee-9c0b-464c-b11a-dfe8f88ebbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat('Total rows:',nrow(train.df),\n",
    "    '\\nTrain rows:',nrow(train.df.train),\n",
    "    '\\nValidation rows',nrow(train.df.validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79326d3e",
   "metadata": {},
   "source": [
    "## Histogram of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66301464",
   "metadata": {},
   "outputs": [],
   "source": [
    "breaks <- seq(from=-0.5, to=5.5, by=1)\n",
    "labels <- c('Barely True', 'False', 'Half-True', 'Mostly-True', 'Not known', 'True')\n",
    "colors <- c('#FF6666','#FF9966', '#FFCC66', '#99FF99' , '#CCCCCC','#00FF99')\n",
    "\n",
    "classes<-hist(x = train.df.train$Labels, \n",
    "     breaks = breaks, \n",
    "     labels = labels,\n",
    "     main = 'Histogram of classes',\n",
    "     xlab = 'Classes',\n",
    "     ylab = 'Count in training set',\n",
    "     col = colors\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b36dbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes <- length(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0213f8d2",
   "metadata": {},
   "source": [
    "## Defining the prior of each classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ffbec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior.classes<-classes$density"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2ac432",
   "metadata": {},
   "source": [
    "## Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a86a256",
   "metadata": {},
   "outputs": [],
   "source": [
    "as.list(get_stopwords())$word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d24368",
   "metadata": {},
   "source": [
    "# Cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78f51b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_tokens <- function(token.df){\n",
    "    word <- ifelse(endsWith(token.df[,1], \"s\"), substr(token.df[,1], 1, nchar(token.df[,1]) - 1), token.df[,1])\n",
    "    word <- ifelse(endsWith(word, \"'\"), substr(word, 1, nchar(word) - 1), word)\n",
    "    word <- ifelse(str_detect(word, \"[0-9]+\"), '--number--', word)\n",
    "    return(as.data.frame(word))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ca812f",
   "metadata": {},
   "source": [
    "# Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59940a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_numbers <- list(tags = c('Barely True', 'False', 'Half-True', 'Mostly-True', 'Not known', 'True'),\n",
    "                     numbers = c(0:5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f05e24",
   "metadata": {},
   "source": [
    "### Vocabulary before feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c2dd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary <- function(train.df.train, tags_numbers){\n",
    "    #take in input a df with 'Text' column containing the messages and 'tag_numbers' the names of the labels\n",
    "    \n",
    "    myframes <- list()\n",
    "\n",
    "    for (i in 1:length(tags_numbers$tags)) {\n",
    "        tag <- tags_numbers$tags[i]\n",
    "\n",
    "        train.df.train %>%\n",
    "        filter(Labels == tags_numbers$numbers[i]) %>%\n",
    "        select(Text) %>%\n",
    "        unnest_tokens(word, Text) %>%\n",
    "        anti_join(get_stopwords(), by = join_by(word)) %>%\n",
    "        cleaning_tokens %>%\n",
    "        arrange(word) %>%\n",
    "        group_by(word) %>%\n",
    "        reframe(counts = n()) %>%\n",
    "        arrange(desc(counts)) %>%\n",
    "        setNames(c(\"word\", tag)) -> myframes[[i]]\n",
    "    } \n",
    "    counts<-purrr::reduce(myframes, dplyr::full_join, by = 'word')\n",
    "    counts %<>% replace(is.na(.),0)\n",
    "    return(counts)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08079115",
   "metadata": {},
   "source": [
    "# Feature Selection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6b4393",
   "metadata": {},
   "source": [
    "## Rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fd36b6",
   "metadata": {},
   "source": [
    "### Ranking per class\n",
    "Ranks by a certain metric (df_rank) per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2407953",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_per_class <- function(df_rank, counts, n_classes, frac = 0.5) {\n",
    "    mywords <- list()\n",
    "    for (i in 2:(n_classes + 1)) {\n",
    "        df_rank[, c(1, i)] %>%\n",
    "            arrange(desc(.[[2]])) %>%\n",
    "            top_frac(frac, .[[2]]) %>%\n",
    "            select(word) -> mywords[[i]]\n",
    "    }\n",
    "    words <- purrr::reduce(mywords, rbind)\n",
    "    words %<>%\n",
    "        unique\n",
    "\n",
    "    counts %>%\n",
    "        right_join(words[\"word\"], by = join_by(word)) -> naive.bayes.vocabulary\n",
    "\n",
    "    return(naive.bayes.vocabulary)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5581383b",
   "metadata": {},
   "source": [
    "### Ranking by mean of classes\n",
    "Ranks by a certain metric (df_rank) by mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868b182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_per_mean <- function(df_rank, counts, n_classes, frac = 0.5) {\n",
    "    df_rank[\"mean\"] <- rowMeans(df_rank[2:(n_classes + 1)])\n",
    "\n",
    "    df_rank %>%\n",
    "        arrange(desc(mean)) %>%\n",
    "        top_frac(frac, mean) %>%\n",
    "        select(word) -> vocabulary.train.features\n",
    "\n",
    "    counts %>%\n",
    "        right_join(vocabulary.train.features[\"word\"], by = join_by(word)) -> naive.bayes.vocabulary\n",
    "\n",
    "    return(naive.bayes.vocabulary)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e67aec",
   "metadata": {},
   "source": [
    "# Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7472e804",
   "metadata": {},
   "source": [
    "## Frequency by mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42697628",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection.frequency_mean <- function(counts, n_classes, frac = 0.5) {\n",
    "    counts %>%\n",
    "        select(-word) %>%\n",
    "        colSums() -> tot_counts_per_class\n",
    "\n",
    "    counts_prob <- cbind(counts[\"word\"], counts[2:(n_classes + 1)]/tot_counts_per_class)\n",
    "    \n",
    "    return(ranking_per_mean(counts_prob, counts, n_classes, frac))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b24507",
   "metadata": {},
   "source": [
    "## Frequency per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eac0a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection.frequency_per_class <- function(counts, n_classes, frac = 0.5) {\n",
    "    return(ranking_per_class(counts, counts, n_classes, frac))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1670b6a0",
   "metadata": {},
   "source": [
    "# Chi squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d35435",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_chi_squared <- function(word, train.df.train, n_classes) {\n",
    "    if (word != \"--number--\") {\n",
    "        train.df.train %>%\n",
    "            group_by(Labels, .drop = FALSE) %>%\n",
    "            filter(grepl(word, Text, ignore.case = TRUE)) %>%\n",
    "            summarise(c = n()) -> yw_c\n",
    "\n",
    "        train.df.train %>%\n",
    "            group_by(Labels, .drop = FALSE) %>%\n",
    "            filter(!grepl(word, Text, ignore.case = TRUE)) %>%\n",
    "            summarise(c = n()) -> nw_c\n",
    "    } else {\n",
    "        train.df.train %>%\n",
    "            group_by(Labels, .drop = FALSE) %>%\n",
    "            filter(grepl(\"[0-9]+\", Text, ignore.case = TRUE)) %>%\n",
    "            summarise(c = n()) -> yw_c\n",
    "\n",
    "        train.df.train %>%\n",
    "            group_by(Labels, .drop = FALSE) %>%\n",
    "            filter(!grepl(\"[0-9]+\", Text, ignore.case = TRUE)) %>%\n",
    "            summarise(c = n()) -> nw_c\n",
    "    }\n",
    "\n",
    "    chi <- vector(length = n_classes)\n",
    "    for (i in 1:n_classes) {\n",
    "        n11 <- yw_c[yw_c$Labels == (i - 1), ]$c\n",
    "        n10 <- sum(yw_c[yw_c$Labels != (i - 1), ]$c)\n",
    "        n01 <- nw_c[yw_c$Labels == (i - 1), ]$c\n",
    "        n00 <- sum(nw_c[nw_c$Labels != (i - 1), ]$c)\n",
    "\n",
    "        chi[i] <- ((n11 + n10 + n01 + n00) * (n11 * n00 - n10 * n01)^2)/((n11 + n01) *\n",
    "            (n11 + n10) * (n10 + n00) * (n01 + n00))\n",
    "    }\n",
    "    chi[is.na(chi)] = 0\n",
    "\n",
    "    return(chi)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60746bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_chi_squared <- function(counts,  train.df.train, n_classes, numCores=numCores) {\n",
    "    \n",
    "    df <- mclapply(X = counts$word, FUN = word_chi_squared, train.df.train = train.df.train,\n",
    "        n_classes = n_classes, mc.cores = numCores)\n",
    "\n",
    "    chi <- cbind(counts[, 1], as.data.frame(do.call(rbind, df)))\n",
    "    \n",
    "    return(chi)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0733f024",
   "metadata": {},
   "source": [
    "## Chi by mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1963eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection.chi_squared_per_mean <- function(counts, train.df.train, n_classes,\n",
    "    frac = 0.5) {\n",
    "\n",
    "    chi<- vocabulary_chi_squared(counts, train.df.train, n_classes, numCores)\n",
    "\n",
    "    return(ranking_per_mean(chi, counts, n_classes, frac))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1934e2c0",
   "metadata": {},
   "source": [
    "## Chi by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e0c4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection.chi_squared_per_class <- function(counts, train.df.train, n_classes,\n",
    "    frac = 0.5) {\n",
    "\n",
    "    chi <- vocabulary_chi_squared(counts, train.df.train, n_classes, numCores)\n",
    "\n",
    "    return(ranking_per_class(chi, counts, n_classes, frac))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788139a2",
   "metadata": {},
   "source": [
    "# Mutual information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20016439",
   "metadata": {},
   "source": [
    "## Mutual information per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83fba86",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_mutual_info <- function(word, train.df.train, n_classes) {\n",
    "    if (word != \"--number--\") {\n",
    "        train.df.train %>%\n",
    "            group_by(Labels, .drop = FALSE) %>%\n",
    "            filter(grepl(word, Text, ignore.case = TRUE)) %>%\n",
    "            summarise(c = n()) -> yw_c\n",
    "\n",
    "        train.df.train %>%\n",
    "            group_by(Labels, .drop = FALSE) %>%\n",
    "            filter(!grepl(word, Text, ignore.case = TRUE)) %>%\n",
    "            summarise(c = n()) -> nw_c\n",
    "    } else {\n",
    "        train.df.train %>%\n",
    "            group_by(Labels, .drop = FALSE) %>%\n",
    "            filter(grepl(\"[0-9]+\", Text, ignore.case = TRUE)) %>%\n",
    "            summarise(c = n()) -> yw_c\n",
    "\n",
    "        train.df.train %>%\n",
    "            group_by(Labels, .drop = FALSE) %>%\n",
    "            filter(!grepl(\"[0-9]+\", Text, ignore.case = TRUE)) %>%\n",
    "            summarise(c = n()) -> nw_c\n",
    "    }\n",
    "\n",
    "    MI <- vector(length = n_classes)\n",
    "    for (i in 1:n_classes) {\n",
    "        n11 <- yw_c[yw_c$Labels == (i - 1), ]$c\n",
    "        n10 <- sum(yw_c[yw_c$Labels != (i - 1), ]$c)\n",
    "        n01 <- nw_c[yw_c$Labels == (i - 1), ]$c\n",
    "        n00 <- sum(nw_c[nw_c$Labels != (i - 1), ]$c)\n",
    "        n1_ <- n11 + n10\n",
    "        n0_ <- n01 + n00\n",
    "        n_1 <- n01 + n11\n",
    "        n_0 <- n10 + n00\n",
    "        n <- n11 + n01 + n10 + n00\n",
    "        MI[i] <- n11/n * log2(n * n11/(n1_ * n_1)) + n01/n * log2(n * n01/(n0_ *\n",
    "            n_1)) + n10/n * log2(n * n10/(n1_ * n_0)) + n00/n * log2(n * n00/(n0_ *\n",
    "            n_0))\n",
    "    }\n",
    "    MI[is.na(MI)] = 0\n",
    "\n",
    "    return(MI)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24877e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_mutual_info <- function(counts,  train.df.train, n_classes, numCores=numCores) {\n",
    "    \n",
    "    df <- mclapply(X = counts$word, FUN = word_mutual_info, train.df.train = train.df.train,\n",
    "        n_classes = n_classes, mc.cores = numCores)\n",
    "\n",
    "    mutual_info <- cbind(counts[, 1], as.data.frame(do.call(rbind, df)))\n",
    "    \n",
    "    return(mutual_info)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3641e2f",
   "metadata": {},
   "source": [
    "## Mutual by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e47745",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection.mutual_info_per_class <- function(counts, train.df.train, n_classes,\n",
    "    frac = 0.5) {\n",
    "\n",
    "    mutual_info <- vocabulary_mutual_info(counts, train.df.train, n_classes, numCores)\n",
    "\n",
    "    return(ranking_per_class(mutual_info, counts, n_classes, frac))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470bcc90",
   "metadata": {},
   "source": [
    "## Mutual by mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34ff518",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection.mutual_info_per_mean <- function(counts, train.df.train, n_classes,\n",
    "    frac = 0.5) {\n",
    "\n",
    "    mutual_info <- vocabulary_mutual_info(counts, train.df.train, n_classes, numCores)\n",
    "\n",
    "    return(ranking_per_mean(mutual_info, counts, n_classes, frac))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a1baef",
   "metadata": {},
   "source": [
    "# Likelihood computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b06bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood.denominator <- function(naive.bayes.vocabulary) {\n",
    "    naive.bayes.vocabulary %>%\n",
    "        select(-word) %>%\n",
    "        colSums() -> tot_counts_per_class\n",
    "\n",
    "    den <- tot_counts_per_class + length(naive.bayes.vocabulary[[1]])\n",
    "    return(den)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492a97a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood <- function(naive.bayes.vocabulary, den) {\n",
    "    likelihood.token <- cbind(naive.bayes.vocabulary[\"word\"], (naive.bayes.vocabulary[2:(n_classes +\n",
    "        1)] + 1)/den)\n",
    "    return(likelihood.token)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4e6b68",
   "metadata": {},
   "source": [
    "## Nayve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537b2a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_tokenize <- function(msg) {\n",
    "    tib <- data.frame(msg)\n",
    "    colnames(tib) <- \"tweet\"\n",
    "    tib %>%\n",
    "        unnest_tokens(word, tweet) %>%\n",
    "        anti_join(get_stopwords(), by = join_by(word)) %>%\n",
    "        cleaning_tokens -> token.list\n",
    "    return(token.list)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86340a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes.probability <- function(token.list, likelihood.token, prior.classes, den, n_classes) {\n",
    "\n",
    "    query_out <- log(as.numeric(prior.classes))\n",
    "    for (i in 1:length(token.list)) {\n",
    "        query <- log(as.numeric(likelihood.token[likelihood.token[\"word\"] == token.list$word[i]][2:(n_classes +\n",
    "            1)]))\n",
    "        if (is.na(query[1])) {\n",
    "            # because if the word is not found, all NA are returned. if the\n",
    "            # word is in the vocabulary the proper likelihood is returned\n",
    "            query <- as.numeric(log(1/den))\n",
    "        }\n",
    "        query_out <- query_out + query\n",
    "    }\n",
    "    query_out <- exp(query_out)\n",
    "    query_out <- query_out/sum(query_out)\n",
    "    return(query_out)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0878402c",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive.bayes <- function(msg, likelihood.token, prior.classes, den, n_classes) {\n",
    "    token.list <- as.vector(tweet_tokenize(msg))\n",
    "    probability <- bayes.probability(token.list, likelihood.token, prior.classes,\n",
    "        den, n_classes)\n",
    "    predicted_class <- which.max(probability) - 1\n",
    "    return(predicted_class)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8eb033",
   "metadata": {},
   "source": [
    "# Training: creating and saving the dfs with words and countings according to feature selection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5f15f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction<-seq(from =0.1, to =1, by=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1be9f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return data.frame with only counted and tokenized words\n",
    "counts <- vocabulary(train.df.train, tags_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ec7e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i in seq_along(fraction)) {\n",
    "    write.csv(feature_selection.frequency_per_class(counts, n_classes, frac = fraction[i]),\n",
    "        file = paste(\"models/frequency_per_class\", fraction[i], \".csv\", sep = \"\"))\n",
    "    write.csv(feature_selection.frequency_mean(counts, n_classes, frac = fraction[i]),\n",
    "        file = paste(\"models/frequency_mean\", fraction[i], \".csv\", sep = \"\"))\n",
    "    write.csv(feature_selection.chi_squared_per_class(counts, n_classes, frac = fraction[i]),\n",
    "        file = paste(\"models/chi_per_class\", fraction[i], \".csv\", sep = \"\"))\n",
    "    write.csv(feature_selection.chi_squared_per_mean(counts, n_classes, frac = fraction[i]),\n",
    "        file = paste(\"models/chi_per_mean\", fraction[i], \".csv\", sep = \"\"))\n",
    "    write.csv(feature_selection.mutual_info_per_class(counts, n_classes, frac = fraction[i]),\n",
    "        file = paste(\"models/mutual_per_class\", fraction[i], \".csv\", sep = \"\"))\n",
    "    write.csv(feature_selection.mutual_info_per_mean(counts, n_classes, frac = fraction[i]),\n",
    "        file = paste(\"models/mutual_per_mean\", fraction[i], \".csv\", sep = \"\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b800d4",
   "metadata": {},
   "source": [
    "# Run all the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67ad431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_per_class <- vector()\n",
    "# for (i in seq_along(fraction)) {\n",
    "#     # Vocabulary optimized with feature selection\n",
    "#     naive.bayes.vocabulary <- feature_selection.ranking_per_class(counts, n_classes,\n",
    "#         frac = fraction[i])\n",
    "\n",
    "#     # Compute denominator of likelihood\n",
    "#     denominator <- likelihood.denominator(naive.bayes.vocabulary)\n",
    "\n",
    "#     # Compute the likelihood for each tokinez and unique word\n",
    "#     likelihood.token <- likelihood(naive.bayes.vocabulary, denominator)\n",
    "\n",
    "#     # Run the prediction\n",
    "#     predicted_classes <- mclapply(X = train.df.validation$Text, FUN = naive.bayes,\n",
    "#         likelihood.token = likelihood.token, prior.classes = prior.classes, den = denominator,\n",
    "#         n_classes = n_classes, mc.cores=numCores)\n",
    "\n",
    "#     # Check % of right predictions\n",
    "#     acc_per_class[i] <- sum(predicted_classes == train.df.validation$Labels)/length(train.df.validation$Labels)\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b341b9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_per_class <- vector()\n",
    "# for (i in seq_along(fraction)) {\n",
    "#     # Vocabulary optimized with feature selection\n",
    "#     naive.bayes.vocabulary <- feature_selection.ranking_per_class(counts, n_classes,\n",
    "#         frac = fraction[i])\n",
    "\n",
    "#     # Compute denominator of likelihood\n",
    "#     denominator <- likelihood.denominator(naive.bayes.vocabulary)\n",
    "\n",
    "#     # Compute the likelihood for each tokinez and unique word\n",
    "#     likelihood.token <- likelihood(naive.bayes.vocabulary, denominator)\n",
    "\n",
    "#     # Run the prediction\n",
    "#     predicted_classes <- mclapply(X = train.df.validation$Text, FUN = naive.bayes,\n",
    "#         likelihood.token = likelihood.token, prior.classes = prior.classes, den = denominator,\n",
    "#         n_classes = n_classes, mc.cores=numCores)\n",
    "\n",
    "#     # Check % of right predictions\n",
    "#     acc_per_class[i] <- sum(predicted_classes == train.df.validation$Labels)/length(train.df.validation$Labels)\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1995fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_freq_mean <- vector()\n",
    "# for (i in seq_along(fraction)) {\n",
    "#     # Vocabulary optimized with feature selection\n",
    "#     naive.bayes.vocabulary <- feature_selection.frequency_mean(counts, n_classes,\n",
    "#         frac = fraction[i])\n",
    "\n",
    "#     # Compute denominator of likelihood\n",
    "#     denominator <- likelihood.denominator(naive.bayes.vocabulary)\n",
    "\n",
    "#     # Compute the likelihood for each tokinez and unique word\n",
    "#     likelihood.token <- likelihood(naive.bayes.vocabulary, denominator)\n",
    "\n",
    "#     # Run the prediction\n",
    "#     predicted_classes <- mclapply(X = train.df.validation$Text, FUN = naive.bayes,\n",
    "#         likelihood.token = likelihood.token, prior.classes = prior.classes, den = denominator,\n",
    "#         n_classes = n_classes, mc.cores=numCores)\n",
    "\n",
    "#     # Check % of right predictions\n",
    "#     acc_freq_mean[i] <- sum(predicted_classes == train.df.validation$Labels)/length(train.df.validation$Labels)\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef925359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(fraction, acc_per_class, type='l', ylim = c(0,1))\n",
    "# lines(fraction, acc_freq_mean, col='red')\n",
    "# legend(0, 1, legend = c(\"freq mean\", \"top per class\"), col = c(\"red\", \"black\"), lty = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7543778",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
